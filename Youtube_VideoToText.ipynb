{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cda5052a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5de1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install youtube-transcript-api transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e1616f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from transformers import pipeline\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffb4ec1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video ID:  Jj1-zb38Yfw\n"
     ]
    }
   ],
   "source": [
    "# Extract the Youtube video ID\n",
    "\n",
    "def extract_video_id(url):\n",
    "    #Using Regex\n",
    "    pattern = r\"(?:v=|youtu\\.be/)([a-zA-Z0-9_-]+)\"\n",
    "    match = re.search(pattern, url)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# Example URL\n",
    "url = \"https://www.youtube.com/watch?v=Jj1-zb38Yfw\"\n",
    "video_id = extract_video_id(url)\n",
    "print(\"Video ID: \", video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a433c182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript length:  7515\n"
     ]
    }
   ],
   "source": [
    "# Fetching transcript\n",
    "transcript_list = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "\n",
    "# Combining individual strings into a single string\n",
    "full_text = \" \".join([item['text'] for item in transcript_list])\n",
    "\n",
    "print(\"Transcript length: \", len(full_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c03202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarization using BART from HuggingFace\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fcdc8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 8 chunks.\n"
     ]
    }
   ],
   "source": [
    "# Spliting transcript into smaller chunks as BART has token limit of ~ 1024 tokens = 1000 words\n",
    "\n",
    "def chunk_text(text, max_length=1000):\n",
    "    return [text[i:i+max_length] for i in range(0, len(text), max_length)]\n",
    "\n",
    "chunks = chunk_text(full_text)\n",
    "print(f\"Split into {len(chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "394c9cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing chunk 1/8...\n",
      "Summarizing chunk 2/8...\n",
      "Summarizing chunk 3/8...\n",
      "Summarizing chunk 4/8...\n",
      "Summarizing chunk 5/8...\n",
      "Summarizing chunk 6/8...\n",
      "Summarizing chunk 7/8...\n",
      "Summarizing chunk 8/8...\n"
     ]
    }
   ],
   "source": [
    "# Summarise each chunk\n",
    "\n",
    "summaries = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Summarizing chunk {i+1}/{len(chunks)}...\")\n",
    "    summary = summarizer(chunk, max_length=100, min_length=10, do_sample=False)[0]['summary_text']\n",
    "    summaries.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1333fda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Summary ✅:\n",
      "Agentic AI is everywhere right now, but is it really new or just a fancier way of saying autonomous AI? I'll show you what truly makes agentic AI different, how it perceives, plans, acts, and learns. This will give you a clear picture of where things are heading in the AI space. Agentic AI is an AI that doesn't just wait for commands. It understands the goal, figures out the steps, uses the right tools, and adapts as it goes. It actually executes the steps making API calls, writes code, sends emails, even runs shell commands. At the center, you have got your AI agent powered by an LLM. It connects to databases to gather context. That's perception. Then it plans and takes action like calling APIs or executing task. Finally, learning. Based on how well things went, the agent stores that experience. Over time, it gets better at handling similar situations. Agentic AI is proactive. It takes the goal and runs with it. It doesn't just assist. It acts, adapts, and learns. It can code push, pull the repo, run test, check for breaking changes. OpenAI's agent SDK is fast moving and tightly integrated with OpenAI too. You give the agent a goal like ship this feature and the framework breaks that into steps, manages memory, routes decision and connects the LLM to tools. Crew AI lets you create teams of agents with defined rules. Autogen by Microsoft help agents collaborate via structured chat flows. All of this orchestration, the back and forth between agents, tools, and goals needs some kind of structure. MCP is a protocol that gives structure to conversations, tool calls, memory access, everything. It's like a smart middle layer, making sure each component in your system understands the full context of what's happening. We are now building systems that not only understand goals, but pursue them. If you are a software engineer, now is the time to explore the space. Start small, pick a task, wire up, and see what it can do.\n"
     ]
    }
   ],
   "source": [
    "# Combine all summaries\n",
    "final_summary = \" \".join(summaries)\n",
    "\n",
    "print(\"Final Summary ✅:\")\n",
    "print(final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9d241dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary saved to video_summary.txt\n"
     ]
    }
   ],
   "source": [
    "with open(\"video_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "          f.write(final_summary)\n",
    "\n",
    "print(\"Summary saved to video_summary.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
